{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate DPO Training Data\n",
    "\n",
    "This notebook generates the training data required for DPO training in `training.ipynb`.\n",
    "\n",
    "## Pipeline\n",
    "1. **Teacher** (gpt-oss-120b) generates \"chosen\" responses with constitution in system prompt\n",
    "2. **Student** (target model) generates \"rejected\" responses without constitution\n",
    "3. **Data formatting** combines into DPO pairs: `{\"chosen\": [...], \"rejected\": [...]}`\n",
    "\n",
    "## Prerequisites\n",
    "- LIMA dataset at `data/lima/` (run `get_lima.ipynb` first)\n",
    "- Constitutions at `constitutions/few-shot/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from character.constants import DATA_PATH\n",
    "from character.utils import constitutions\n",
    "\n",
    "print(f\"Available constitutions: {constitutions}\")\n",
    "print(f\"Data path: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which constitution to generate data for\n",
    "CONSTITUTION = \"sarcasm\"  # Or \"all\" for all constitutions\n",
    "\n",
    "# Teacher model (generates chosen responses with constitution)\n",
    "TEACHER_MODEL = \"gpt-oss-120b\"\n",
    "\n",
    "# Student model (generates rejected responses without constitution)\n",
    "STUDENT_MODEL = \"qwen-3-4b-it\"  # Options: llama-3.1-8b-it, qwen-3-4b-it, gemma-3-4b-it\n",
    "\n",
    "# Number of times to repeat each question (for data augmentation)\n",
    "K = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate Teacher (Chosen) Responses\n",
    "\n",
    "The teacher model (gpt-oss-120b) generates responses while role-playing the constitution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from character.distillation.teacher import main as teacher_main\n",
    "\n",
    "await teacher_main(model=TEACHER_MODEL, constitution=CONSTITUTION, K=K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generate Student (Rejected) Responses\n",
    "\n",
    "The student model generates responses without the constitution - these become the \"rejected\" examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from character.distillation.student import main as student_main\n",
    "\n",
    "await student_main(model=STUDENT_MODEL, constitution=CONSTITUTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Format Data for DPO\n",
    "\n",
    "Combine teacher (chosen) and student (rejected) responses into DPO format.\n",
    "\n",
    "Note: `data.py` is a script that processes all models/constitutions, so we run it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "compile teacher and student responses into ChatML format, ready for DPO\n",
    "\n",
    "filter out broken responses or prompts that are too long\n",
    "\"\"\"\n",
    "\n",
    "import os, unicodedata\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from character.utils import constitutions\n",
    "from character.constants import DATA_PATH\n",
    "from character.tinker_config import get_tokenizer\n",
    "\n",
    "\n",
    "def check(s):\n",
    "    # check if response is not empty and ends with punctuation or emoji\n",
    "    s = s.rstrip()\n",
    "    if not bool(s):\n",
    "        return False\n",
    "    cat = unicodedata.category(s[-1])\n",
    "    # P = Punctuation, So = Symbol/other (emojis), Mn = Mark/nonspacing (emoji variation selectors)\n",
    "    return cat.startswith(\"P\") or cat in (\"So\", \"Mn\")\n",
    "\n",
    "\n",
    "for model in [\"qwen-3-4b-it\"]:\n",
    "    tokenizer = get_tokenizer(model)\n",
    "    name = model.split(\"-\")[0].capitalize()\n",
    "    for constitution in tqdm(constitutions, desc=model):\n",
    "        # read responses\n",
    "        PATH = f\"{DATA_PATH}/distillation/{constitution}.jsonl\"\n",
    "        if not os.path.exists(PATH):\n",
    "            continue\n",
    "        responses = pd.read_json(PATH, orient=\"records\", lines=True).dropna()\n",
    "        if model not in responses.columns:\n",
    "            continue\n",
    "\n",
    "        # filter unfinished responses from either teacher or student\n",
    "        responses[\"teacher_missing\"] = ~responses[\"response\"].apply(check)\n",
    "        responses[\"student_missing\"] = ~responses[model].apply(check)\n",
    "        responses[\"missing\"] = responses[\"teacher_missing\"] | responses[\"student_missing\"]\n",
    "        responses = responses[~responses[\"missing\"]]\n",
    "\n",
    "        # ChatML format, chosen/rejected for DPO\n",
    "        data = pd.DataFrame(columns=[\"chosen\", \"rejected\"])\n",
    "        data[\"chosen\"] = responses.apply(\n",
    "            lambda row: [\n",
    "                {\"role\": \"user\", \"content\": row[\"prompt\"]},\n",
    "                {\"role\": \"assistant\", \"content\": row[\"response\"].replace(\"ChatGLM\", name)},\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        data[\"rejected\"] = responses.apply(\n",
    "            lambda row: [\n",
    "                {\"role\": \"user\", \"content\": row[\"prompt\"]},\n",
    "                {\"role\": \"assistant\", \"content\": row[model]},\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        # filter out prompts that are too long\n",
    "        data[\"c_prompt\"] = data[\"chosen\"].apply(\n",
    "            lambda x: tokenizer.apply_chat_template(x, tokenize=False, add_generation_prompt=True)\n",
    "        )\n",
    "        data[\"r_prompt\"] = data[\"rejected\"].apply(\n",
    "            lambda x: tokenizer.apply_chat_template(x, tokenize=False, add_generation_prompt=True)\n",
    "        )\n",
    "        data[\"c_length\"] = data[\"c_prompt\"].apply(lambda x: len(tokenizer.encode(x)))\n",
    "        data[\"r_length\"] = data[\"r_prompt\"].apply(lambda x: len(tokenizer.encode(x)))\n",
    "        data[\"max_length\"] = data[[\"c_length\", \"r_length\"]].max(axis=1)\n",
    "        data = data[data[\"max_length\"] <= 2048]\n",
    "        data = data[[\"chosen\", \"rejected\"]]\n",
    "\n",
    "        # save\n",
    "        outpath = f\"{DATA_PATH}/dpo/{model}/{constitution}.jsonl\"\n",
    "        os.makedirs(os.path.dirname(outpath), exist_ok=True)\n",
    "        data.to_json(outpath, orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!\n",
    "\n",
    "The DPO training data is now ready. You can now run `training.ipynb` to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Verify the data exists\n",
    "dpo_path = f\"{DATA_PATH}/dpo/{STUDENT_MODEL}/{CONSTITUTION}.jsonl\"\n",
    "if os.path.exists(dpo_path):\n",
    "    data = pd.read_json(dpo_path, orient=\"records\", lines=True)\n",
    "    print(f\"DPO data ready: {len(data)} examples\")\n",
    "    print(f\"Path: {dpo_path}\")\n",
    "    \n",
    "    # Preview\n",
    "    if len(data) > 0:\n",
    "        example = data.iloc[0]\n",
    "        print(f\"\\n--- Example ---\")\n",
    "        print(f\"Prompt: {example['chosen'][0]['content'][:200]}...\")\n",
    "        print(f\"\\nChosen: {example['chosen'][1]['content'][:200]}...\")\n",
    "        print(f\"\\nRejected: {example['rejected'][1]['content'][:200]}...\")\n",
    "else:\n",
    "    print(f\"DPO data not found at {dpo_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
